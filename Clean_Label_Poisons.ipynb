{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21c0335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc7affda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_directory(Specie,directory):\n",
    "    \"\"\"\n",
    "    Returns an numpy array of the images in a folder directory\n",
    "    Parameters\n",
    "    ----------\n",
    "    Specie : string\n",
    "        just the name of the class - used for reporting\n",
    "    directory : string\n",
    "        directory where the image files are in there (jpeg or any other format)\n",
    "    Returns\n",
    "    -------\n",
    "    res: ndarray\n",
    "        all of the images in the directory dumped into a numpy array\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for file in listdir(directory):\n",
    "        thisOne = cv2.imread(directory+file)\n",
    "        res.append(thisOne)\n",
    "    res = np.array(res)\n",
    "    print('Done loading %d %s\\'s !'%(len(res),Specie))\n",
    "    print(res[:2],Specie)\n",
    "    print(res.dtype)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3869c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(X):\n",
    "    \"\"\"\n",
    "    this method takes the data input images and removes those that do not have a 3rd dimension\n",
    "     to prevent issues with inception and returns the clean numpy array\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        images all in one huge numpy array\n",
    "    Returns\n",
    "    -------\n",
    "    res: ndarray\n",
    "        all of the images without the ones which have less than 3 dimensions\n",
    "    \"\"\"\n",
    "\n",
    "    indices = []\n",
    "    for i,d in enumerate(X):\n",
    "        if d.ndim !=3:\n",
    "            indices.append(i)\n",
    "            print('removing index %d with shape:'%i,d.shape)\n",
    "    \n",
    "    if len(indices) > 0:\n",
    "        newX = np.delete(X,indices)\n",
    "    else:\n",
    "        newX = X\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8cf4fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "graphDir=\"D:/Courses/Spring 2022/Trustworthy ML/Final_project/inceptionV3/classify_image_graph_def.pb\"\n",
    "def create_graph(graphDir=None):\n",
    "    \"\"\"\"Creates a graph from saved GraphDef file and returns a saver.\"\"\"\n",
    "    # Creates graph from saved graph_def.pb.\n",
    "    # if graph directory is not given, it is the default\n",
    "    if graphDir == None:\n",
    "        graphDir = \"D:/Courses/Spring 2022/Trustworthy ML/Final_project/inceptionV3/classify_image_graph_def.pb\"\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        with tf.compat.v1.gfile.FastGFile(graphDir, 'rb') as f:\n",
    "            graph_def = tf.compat.v1.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            _ = tf.import_graph_def(graph_def, name='')\n",
    "    return sess.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b55f433",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "def get_feat_reps(X,class_t):\n",
    "    \"\"\"\n",
    "    Returns the feature representation of some images by looking at the penultimate layer of inception-v3\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        input images all put in a numpy array\n",
    "    class_t : string\n",
    "        class of the images which we are doing feature extractions for.\n",
    "        Note that this is only used for printing summary of progress. So just give it some\n",
    "        random name if you don't care\n",
    "    Returns\n",
    "    -------\n",
    "    res: ndarray\n",
    "        feature represntation of the input images X. should have same length of X\n",
    "    \"\"\"\n",
    "    #parameters\n",
    "    feat_tensor_name = 'pool_3:0'\n",
    "    input_tensor_name = 'DecodeJpeg:0'\n",
    "\n",
    "    #get a session and create the graph\n",
    "    sess = tf.compat.v1.Session()\n",
    "    create_graph()\n",
    "\n",
    "    #get needed tensors\n",
    "    feat_tensor = sess.graph.get_tensor_by_name(feat_tensor_name)\n",
    "    input_tensor = sess.graph.get_tensor_by_name(input_tensor_name)\n",
    "\n",
    "    #get the feature representations\n",
    "    res = []\n",
    "    print(X[:3])\n",
    "    for i,x in enumerate(X):\n",
    "        res.append(sess.run(feat_tensor, feed_dict={input_tensor:x}))\n",
    "        if i % 50 == 0:\n",
    "            print('finished %d\\'th example of %s'%(i,class_t))\n",
    "    res = np.array(res)\n",
    "\n",
    "    #rest graph and close session to free memory\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    sess.close()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73f27770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "def id_duplicates_of_training_from_test(X_test,X_training, threshold = 3.5):\n",
    "    \"\"\"\n",
    "    Returns the ids for the duplicates of training in test\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_test : ndarray\n",
    "        the feature represenatons of the test data.\n",
    "    X_training : ndarray\n",
    "        the feature represenatons of the training data\n",
    "    threshold : float\n",
    "        threshold for reporting the similarity\n",
    "    Returns\n",
    "    -------\n",
    "    ids : list of integer\n",
    "        The difference in feature space measure by the 2-norm\n",
    "    \"\"\"\n",
    "    list_ind = []\n",
    "    for i in range(len(X_test)):\n",
    "        distsToTargs = cdist(np.expand_dims(X_test[i], axis = 0), X_training)\n",
    "        # print distsToTargs\n",
    "        report_inds = np.argwhere(distsToTargs <= threshold)\n",
    "        if len(report_inds) > 0:\n",
    "            print (report_inds)\n",
    "            print(distsToTargs[0][report_inds])\n",
    "        if len(np.argwhere(distsToTargs == 0.)) > 0:\n",
    "            list_ind.append(i)\n",
    "    print(\"number of test examples removed due to having duplicates in training data is:%d\"%len(list_ind))\n",
    "    return list_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b78079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def load_bottleNeckTensor_data(directory=None, saveEm=False, random_state=123, train_size=800):\n",
    "    \"\"\"\n",
    "    Returns the train-test splits of images and their feature representations.\n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : string, optional\n",
    "        directory that the feature representations and image numpy formats are saved.\n",
    "    saveEm : Boolean, optional\n",
    "        whether to save the training and test data on disk or not\n",
    "    random_state : integer, optional\n",
    "        random seed used in train_test_split for splitting the training and test data\n",
    "    train_size : integer, optional\n",
    "        the number of elements in the training data for each of the classes. The remaining\n",
    "        would be assigned to the test data\n",
    "    Returns\n",
    "    -------\n",
    "    X_tr_feats, X_tst_feats, X_tr_inp, X_tst_inp, Y_tr, Y_tst : ndarray\n",
    "        Arrays used for training.\n",
    "    \"\"\"\n",
    "    #some parameters \n",
    "    directorySaving = 'D:/Courses/Spring 2022/Trustworthy ML/Final_project/XY/' #directory to save the X and Ys\n",
    "    allDogs = 'dogInput.npy'\n",
    "    allCats  = 'catInput.npy'\n",
    "    dog_X_feats = 'dogFeats.npy'\n",
    "    cat_X_feats = 'catFeats.npy'\n",
    "    if directory != None:\n",
    "        dog_X_feats = directory + dog_X_feats\n",
    "        cat_X_feats = directory + cat_X_feats\n",
    "        allDogs = directory + allDogs\n",
    "        allCats = directory + allCats\n",
    "\n",
    "    \n",
    "    #load the data\n",
    "    dog_x_feats = np.load(dog_X_feats,allow_pickle=True)\n",
    "    cat_x_feats = np.load(cat_X_feats,allow_pickle=True)\n",
    "    allCats = np.load(allCats,allow_pickle=True)\n",
    "    allDogs = np.load(allDogs,allow_pickle=True)\n",
    "    \n",
    "    #do train and test split number of training dogs and number of training fishes = 800 from each class\n",
    "    x_d_tr, x_d_tst, y_d_tr, y_d_tst, inp_d_tr, inp_d_tst = train_test_split(dog_x_feats, np.zeros(len(dog_x_feats)), allDogs ,train_size=train_size, random_state=random_state)\n",
    "    x_f_tr, x_f_tst, y_f_tr, y_f_tst, inp_f_tr, inp_f_tst = train_test_split(cat_x_feats, np.ones(len(cat_x_feats)),allCats, train_size=train_size, random_state=random_state)\n",
    "    \n",
    "    assert len(x_d_tr) + len(x_d_tst) == len(dog_x_feats), \"There is some issue with the spliting\"\n",
    "    assert len(inp_d_tr) + len(inp_d_tst) == len(dog_x_feats), \"There's issues with splitting of the input images - maybe there is an issue with the raw images\"\n",
    "    \n",
    "    #concatenate all of the X's\n",
    "    X_tr_feats = np.squeeze(np.concatenate((x_d_tr, x_f_tr), axis=0))\n",
    "    X_tst_feats = np.squeeze(np.concatenate((x_d_tst, x_f_tst), axis=0))\n",
    "    X_tr_inp = np.squeeze(np.concatenate((inp_d_tr, inp_f_tr), axis=0))\n",
    "    X_tst_inp = np.squeeze(np.concatenate((inp_d_tst, inp_f_tst), axis=0))\n",
    "    #make a Y vector\n",
    "    Y_tr = np.concatenate((y_d_tr,y_f_tr),axis=0)\n",
    "    Y_tst = np.concatenate((y_d_tst,y_f_tst),axis=0)\n",
    "\n",
    "    #remove the duplicates of the test data which are already present in the training data\n",
    "    ids_for_test_removal = id_duplicates_of_training_from_test(X_test=X_tst_feats,X_training=X_tr_feats, threshold = 3.5)\n",
    "    print (ids_for_test_removal)\n",
    "    #sort the ids in descending order\n",
    "    ids_for_test_removal.sort(reverse=True)\n",
    "    for k in ids_for_test_removal:\n",
    "        X_tst_feats = np.delete(X_tst_feats,k,axis=0)\n",
    "        X_tst_inp = np.delete(X_tst_inp,k,axis=0)\n",
    "        Y_tst = np.delete(Y_tst,k,axis=0)\n",
    "\n",
    "    \n",
    "    all_datas = ['X_tr_feats', 'X_tst_feats', 'X_tr_inp', 'X_tst_inp', 'Y_tr', 'Y_tst']\n",
    "    if saveEm:\n",
    "        if not os.path.exists(directorySaving):\n",
    "            os.makedirs(directorySaving)\n",
    "        for d in all_datas:\n",
    "            np.save(directorySaving+d+'.npy',eval(d))\n",
    "            print(\"Saved\")\n",
    "    \n",
    "    return X_tr_feats, X_tst_feats, X_tr_inp, X_tst_inp, Y_tr, Y_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91457697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam_one_step(sess,grad_op,m,v,t,currentImage,featRepTarget,tarFeatRepPL,inputCastImgTensor,learning_rate,beta_1=0.9, beta_2=0.999, eps=1e-8):\n",
    "    t += 1\n",
    "    grad_t = np.squeeze(np.array(sess.run(grad_op, feed_dict={inputCastImgTensor: currentImage, tarFeatRepPL:featRepTarget})))\n",
    "    m = beta_1 * m + (1-beta_1)*grad_t\n",
    "    v = beta_2 * v + (1-beta_2)*grad_t*grad_t\n",
    "    m_hat = m/(1-beta_1**t)\n",
    "    v_hat = v/(1-beta_2**t)\n",
    "    currentImage -= learning_rate*m_hat/(np.sqrt(v_hat)+eps)\n",
    "    return currentImage,m,v,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1227dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_forward(sess,grad_op,inputCastImgTensor, currentImage,featRepCurrentImage,featRepTarget,tarFeatRepPL,learning_rate=0.01):\n",
    "    \"\"\"helper function doing the forward step in the FWD-BCKWD splitting algorithm\"\"\"\n",
    "    grad_now = sess.run(grad_op, feed_dict={inputCastImgTensor: currentImage, tarFeatRepPL:featRepTarget})      #evaluate the gradient at the current point\n",
    "    currentImage = currentImage - learning_rate*np.squeeze(np.array(grad_now))                                  #gradient descent\n",
    "    return currentImage                                                                                         #get the new current point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c1c4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_backward(baseInpImage,currentImage,coeff_sim_inp,learning_rate,eps=0.1,do_clipping=True,inf_norm=False):\n",
    "    \"\"\"helper function doing the backward step in the FWD-BCKWD splitting algorithm\"\"\"\n",
    "    if inf_norm:\n",
    "        back_res = baseInpImage + np.maximum(np.minimum(currentImage - baseInpImage,eps) ,-eps)\n",
    "    else:\n",
    "        back_res = (coeff_sim_inp*learning_rate*baseInpImage + currentImage)/(coeff_sim_inp*learning_rate + 1)\n",
    "    if do_clipping:\n",
    "        back_res = np.clip(back_res,0,255)\n",
    "    return back_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "749339ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_optimization(targetImg, baseImg, MaxIter=200,coeffSimInp=0.25, saveInterim=False, imageID=0, objThreshold = 2.9):\n",
    "    \"\"\"\n",
    "    Returns the poison image and the difference between the poison and target in feature space.\n",
    "    Parameters\n",
    "    ----------\n",
    "    targetImg : ndarray\n",
    "        the input image of the target from the  test set.\n",
    "    baseImg : ndarray\n",
    "        the input image of the base class (this should have a differet class than the target)\n",
    "    MaxIter : integer\n",
    "        this is the maximum number of fwd backward iterations\n",
    "    coeffSimInp : flaot\n",
    "        the coefficient of similarity to the base image in input image space relative to the \n",
    "        similarity to the feature representation of the target when everything is normalized\n",
    "        the objective function of the optimization is:\n",
    "                || f(x)-f(t) ||^2 + coeffSimInp * || x-b ||^2\n",
    "    objThreshold: float\n",
    "        the threshold for the objective functoin, when the obj func falls below this, the \n",
    "        optimization is stopped even if the MaxIter is not met.\n",
    "    Returns\n",
    "    -------\n",
    "    old_image, finalDiff : ndarray, float\n",
    "        The poison in uin8 format\n",
    "        The difference in feature space measure by the 2-norm\n",
    "    \"\"\"\n",
    "\n",
    "    #parameters:\n",
    "    Adam = False\n",
    "    decayCoef = 0.5                 #decay coeffiencet of learning rate\n",
    "    learning_rate = 500.0*255      #iniital learning rate for optimiz\n",
    "    stopping_tol = 1e-10            #for the relative change\n",
    "    EveryThisNThen = 20             #for printing reports\n",
    "    M = 40                          #used for getting the average of last M objective function values\n",
    "    BOTTLENECK_TENSOR_NAME = 'pool_3/_reshape'\n",
    "    INPUT_TENSOR_NAME = 'DecodeJpeg:0'\n",
    "\n",
    "    #calculations for getting a reasonable value for coefficient of similarity of the input to the base image\n",
    "    bI_shape = np.squeeze(baseImg).shape\n",
    "    coeff_sim_inp = coeffSimInp*(2048/float(bI_shape[0]*bI_shape[1]*bI_shape[2]))**2\n",
    "    print('coeff_sim_inp is:', coeff_sim_inp)\n",
    "\n",
    "    #load the inception v3 graph\n",
    "    sess = sess = tf.compat.v1.Session()\n",
    "    graph = create_graph()\n",
    "\n",
    "    #add some of the needed operations\n",
    "    featRepTensor = graph.get_tensor_by_name(BOTTLENECK_TENSOR_NAME+':0')\n",
    "    inputImgTensor = sess.graph.get_tensor_by_name(INPUT_TENSOR_NAME)\n",
    "    inputCastImgTensor = graph.get_tensor_by_name('Cast:0')#'ResizeBilinear:0')\n",
    "    tarFeatRepPL = tf.compat.v1.placeholder(tf.float32,[None,2048])\n",
    "    forward_loss = tf.norm(featRepTensor - tarFeatRepPL)\n",
    "    grad_op = tf.compat.v1.gradients(forward_loss, inputCastImgTensor)\n",
    "\n",
    "    #initializations\n",
    "    last_M_objs = []\n",
    "    rel_change_val = 1e5\n",
    "    baseImg = sess.run(inputCastImgTensor, feed_dict={inputImgTensor: baseImg})         #get cast:0 output of input base image\n",
    "    targetFeatRep = sess.run(featRepTensor, feed_dict={inputImgTensor: targetImg})      #get the feature reprsentation of the target\n",
    "    old_image = baseImg                                                                 #set the poison's starting point to be the base image\n",
    "    old_featRep = sess.run(featRepTensor, feed_dict={inputCastImgTensor: baseImg})      #get the feature representation of current poison\n",
    "    old_obj = np.linalg.norm(old_featRep - targetFeatRep) + coeff_sim_inp*np.linalg.norm(old_image - baseImg)\n",
    "    last_M_objs.append(old_obj)\n",
    "\n",
    "    #intializations for ADAM\n",
    "    if Adam:\n",
    "        m = 0.\n",
    "        v = 0.\n",
    "        t = 0\n",
    "\n",
    "    #optimization being done here\n",
    "    for iter in range(MaxIter):\n",
    "        #save images every now and then\n",
    "        if iter % EveryThisNThen == 0:\n",
    "            the_diffHere = np.linalg.norm(old_featRep - targetFeatRep)      #get the diff\n",
    "            theNPimg = old_image                                            #get the image\n",
    "            print(\"iter: %d | diff: %.3f | obj: %.3f\"%(iter,the_diffHere,old_obj))\n",
    "            print(\" (%d) Rel change =  %0.5e   |   lr = %0.5e |   obj = %0.10e\"%(iter,rel_change_val,learning_rate,old_obj))\n",
    "            if saveInterim:\n",
    "                name = '%d_%d_%.5f.jpeg'%(imageID,iter,the_diffHere)\n",
    "                misc.imsave('./interimPoison/'+name, np.squeeze(old_image).astype(np.uint8))\n",
    "            # plt.imshow(np.squeeze(old_image).astype(np.uint8))\n",
    "            # plt.show()\n",
    "\n",
    "        # forward update gradient update\n",
    "        if Adam:\n",
    "            new_image,m,v,t = adam_one_step(sess=sess,grad_op=grad_op,m=m,v=v,t=t,currentImage=old_image,featRepTarget=targetFeatRep,tarFeatRepPL=tarFeatRepPL,inputCastImgTensor=inputCastImgTensor,learning_rate=learning_rate)\n",
    "        else:\n",
    "            new_image = do_forward(sess=sess,grad_op=grad_op,inputCastImgTensor=inputCastImgTensor, currentImage=old_image,featRepCurrentImage=old_featRep,featRepTarget=targetFeatRep,tarFeatRepPL=tarFeatRepPL,learning_rate=learning_rate)\n",
    "        \n",
    "        # The backward step in the forward-backward iteration\n",
    "        new_image = do_backward(baseInpImage=baseImg,currentImage=new_image,coeff_sim_inp=coeff_sim_inp,learning_rate=learning_rate,eps=0.1)\n",
    "        \n",
    "        # check stopping condition:  compute relative change in image between iterations\n",
    "        rel_change_val =  np.linalg.norm(new_image-old_image)/np.linalg.norm(new_image)\n",
    "        if (rel_change_val<stopping_tol) or (old_obj<=objThreshold):\n",
    "            break\n",
    "\n",
    "        # compute new objective value\n",
    "        new_featRep = sess.run(featRepTensor, feed_dict={inputCastImgTensor: new_image})\n",
    "        new_obj = np.linalg.norm(new_featRep - targetFeatRep) + coeff_sim_inp*np.linalg.norm(new_image - baseImg)\n",
    "        \n",
    "        if Adam:\n",
    "            learning_rate = 0.1*255.\n",
    "            old_image = new_image\n",
    "            old_obj = new_obj\n",
    "            old_featRep = new_featRep\n",
    "        else:\n",
    "\n",
    "            avg_of_last_M = sum(last_M_objs)/float(min(M,iter+1)) #find the mean of the last M iterations\n",
    "            # If the objective went up, then learning rate is too big.  Chop it, and throw out the latest iteration\n",
    "            if  new_obj >= avg_of_last_M and (iter % M/2 == 0):\n",
    "                learning_rate *= decayCoef\n",
    "                new_image = old_image\n",
    "            else:\n",
    "                old_image = new_image\n",
    "                old_obj = new_obj\n",
    "                old_featRep = new_featRep\n",
    "                \n",
    "            if iter < M-1:\n",
    "                last_M_objs.append(new_obj)\n",
    "            else:\n",
    "                #first remove the oldest obj then append the new obj\n",
    "                del last_M_objs[0]\n",
    "                last_M_objs.append(new_obj)\n",
    "            if iter > MaxIter:\n",
    "                m = 0.\n",
    "                v = 0.\n",
    "                t = 0\n",
    "                Adam = True\n",
    "\n",
    "    finalDiff = np.linalg.norm(old_featRep - targetFeatRep)\n",
    "    print('final diff: %.3f | final obj: %.3f'%(finalDiff,old_obj))\n",
    "    #close the session and reset the graph to clear memory\n",
    "    sess.close()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    return np.squeeze(old_image).astype(np.uint8), finalDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d01cc59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_to_target_from_class(classBase,targetFeatRep,allTestFeatReps, allTestClass):\n",
    "    \"\"\"\n",
    "    Returns an index within the allTestFeatReps matrix for which is the closes to the target in feature spacee and belongs to the base class\n",
    "    Parameters\n",
    "    ----------\n",
    "    classBase : int\n",
    "        the class for the base class - we want the target to be misclassified as this class.\n",
    "    targetFeatRep : ndarray\n",
    "        the feature representation of the target image (2048 for inception-v3)\n",
    "    allTestFeatReps : ndarray\n",
    "        feature reprsentation of all the test data\n",
    "    allTestClass : ndarray\n",
    "        array contatining the class for all of the test data. In a binary classification task, it would be an array of 0s and 1s\n",
    "    Returns\n",
    "    -------\n",
    "    ind_min : int\n",
    "        The index of the poison base in test data. The poison base is from the base class and has the smallest distance to the target in feature space\n",
    "        The difference in feature space measured by the 2-norm\n",
    "    \"\"\"\n",
    "    if allTestFeatReps.ndim > 2: #if needed, squeeze the feat rep\n",
    "        allTestFeatReps = np.squeeze(allTestFeatReps)\n",
    "    assert allTestFeatReps.ndim == 2, 'the feat rep matrix should have 2 dimensions it has %d dimensions...'%allTestFeatReps.ndim\n",
    "    \n",
    "    possible_indices = np.argwhere(allTestClass == classBase)\n",
    "    featRepCandidantes = np.squeeze(allTestFeatReps[possible_indices])\n",
    "    \n",
    "    #calculate distance from the target to the candidates:\n",
    "    print(featRepCandidantes.ndim,targetFeatRep.ndim)\n",
    "    Dists = cdist(featRepCandidantes,np.expand_dims(targetFeatRep,axis=0))\n",
    "    min_ind = Dists.argmin()\n",
    "    print('distance from base to target in feat space:',Dists[min_ind])\n",
    "    \n",
    "    return possible_indices[min_ind][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a68a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_one_hot(nclasses,y):\n",
    "    return np.eye(nclasses)[y.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8839d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_mini_batches(X_input,Y_input,batch_size):\n",
    "    n_train = X_input.shape[0]\n",
    "    for ndx in range(0, n_train, batch_size):\n",
    "        yield X_input[ndx:min(ndx + batch_size, n_train)], Y_input[ndx:min(ndx + batch_size, n_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b3244f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_last_layer_of_inception(targetFeatRep,poisonInpImage,poisonClass,X_tr,Y_tr,Y_validation,X_validation,cold=True):\n",
    "    \"\"\"\n",
    "    This function does training for the last layer of inception-v3. It either performs a cold start in which it starts from a pre-saved graph or\n",
    "    does a warm start during which it again starts from a presaved graph but the pre-saved graph is for an already pretrained net.\n",
    "    Parameters\n",
    "    ----------\n",
    "    targetFeatRep : ndarray of type float32\n",
    "        the feature representation of the target.\n",
    "    poisonInpImage : ndarray of type uint8\n",
    "        the input image for the poison . This will be fed to the pool_3 input\n",
    "    poisonClass : int\n",
    "        the class of the poison - this should be the correct label for the poison/the class that we would like our target to be from\n",
    "    X_tr : ndarray, float32\n",
    "        array containing all of the training data. This is the feature representation of the data. It would have dim: n_t X 2048 for inception-v3\n",
    "    Y_tr : ndarray, int\n",
    "        array containing the class labels of the training data. the dimensions would be n_t. All the values in the array are 0s or 1s\n",
    "    Y_validation: ndarray, int\n",
    "        similar to the Y_tr but contatining the test data\n",
    "    X_validation: ndarray, float32\n",
    "        similar to X_tr but contatining the test data\n",
    "    cold: Boolean\n",
    "        if True, the evaluation will be based using cold start and not pretrained weights.\n",
    "        if False, the evaluation would be using warm start. It starts from a set of weights that are pretrained.    \n",
    "    Returns\n",
    "    -------\n",
    "    ind_min : int\n",
    "        The index of the poison base in test data. The poison base is from the base class and has the smallest distance to the target in feature space\n",
    "        The difference in feature space measured by the 2-norm\n",
    "    \"\"\"\n",
    "    # parameters\n",
    "    learning_rate = 0.01 #note that this learning rate is for only the cold start. If doing warm start, we will be using the last learning rate used during pretraining the weights (0.01 by default)\n",
    "    mini_batch_size = 32\n",
    "    epocs = 100\n",
    "    classes = ['dog','cat']\n",
    "    how_many_training_steps = 10000\n",
    "    eval_step_interval = 100\n",
    "    \n",
    "    #fixing target shapes\n",
    "    Y_target = np.ones((1,2))\n",
    "    Y_target[0,int(poisonClass)] = 0.\n",
    "    Y_poison = np.zeros((1,2))\n",
    "    Y_poison[0,int(poisonClass)] = 1.\n",
    "    targetFeatRep = targetFeatRep.reshape(1,len(targetFeatRep))\n",
    "    print(\"Y_target is:\",Y_target)\n",
    "    \n",
    "    #do initializations\n",
    "    tf.reset_default_graph()                                    #reset the default graph to free up memory\n",
    "    sess = tf.Session()                                         #get session\n",
    "    random_permutation = np.arange(len(X_tr)+1)                 #for training - we add one to the number of training data to account for the poison\n",
    "    \n",
    "    #based on whether we are doing cold start or warm start, load the appropriate graph\n",
    "    if cold: \n",
    "        saver = tf.train.import_meta_graph('./dog_v_cat_cold_graph/dog_v_cat_cold_graph.meta')\n",
    "        saver.restore(sess,tf.train.latest_checkpoint('./dog_v_cat_cold_graph/'))\n",
    "        reportWeightChanges = False\n",
    "    else:\n",
    "        saver = tf.train.import_meta_graph('./dog_v_cat_hot_graph/dog_v_cat_hot_graph.meta')\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('./dog_v_cat_hot_graph/'))\n",
    "        reportWeightChanges = True\n",
    " \n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    #getting feature representation of the poison - we need to get this first before adding it to the training data\n",
    "    feat_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "    input_tensor = sess.graph.get_tensor_by_name('DecodeJpeg:0')#'Cast:0')\n",
    "    poisonFeatRep = np.expand_dims(np.squeeze(sess.run(feat_tensor, feed_dict={input_tensor: poisonInpImage})), axis=0)\n",
    "    \n",
    "    #append the training data and add the poison to the end of it\n",
    "    X_tr = np.vstack((X_tr,poisonFeatRep))\n",
    "    Y_tr = np.append(Y_tr,poisonClass)\n",
    "    if X_tr.ndim > 2:\n",
    "        X_tr = np.squeeze(n_dim)\n",
    "\n",
    "    # getting required tensors or making required ops as needed.\n",
    "    X_Bottleneck = sess.graph.get_tensor_by_name('X_bottleneck:0')\n",
    "    Y_true = sess.graph.get_tensor_by_name('Y_true:0')\n",
    "    Ylogits = sess.graph.get_tensor_by_name('logits:0')\n",
    "    biasvar = sess.graph.get_tensor_by_name('final_biases:0')\n",
    "    weightsvar = sess.graph.get_tensor_by_name('final_weights:0')\n",
    "    cross_entropy = sess.graph.get_tensor_by_name('cross_entropy_mean_2class:0')\n",
    "    evaluation_step = sess.graph.get_tensor_by_name('eval_step_2class:0')\n",
    "    print(\"********>>>>>>\",sess.run(evaluation_step,feed_dict={X_Bottleneck: X_validation,Y_true: encode_one_hot(len(classes), Y_validation)}))\n",
    "    if not cold:\n",
    "        train_step = sess.graph.get_operation_by_name('Adam')\n",
    "        print(\"hot start\")\n",
    "    else:\n",
    "        print(\"cold start\")\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate, name='ADMM').minimize(cross_entropy) #, var_list=[biasvar, weightsvar] # GradientDescent\n",
    "        sess.run(tf.global_variables_initializer())             #also intialize the variables if doing cold start. they are random or somewhat random numbers\n",
    "    correct_prediction = tf.equal(tf.argmax(Ylogits, 1), tf.argmax(Y_true, 1))\n",
    "    class_probs = tf.nn.softmax(Ylogits)\n",
    "\n",
    "\n",
    "    print(\"********>>>>>>\",sess.run(evaluation_step,feed_dict={X_Bottleneck: X_validation,Y_true: encode_one_hot(len(classes), Y_validation)}))\n",
    "    # doing the training\n",
    "    n_train = X_tr.shape[0]\n",
    "    i=0\n",
    "    if reportWeightChanges:\n",
    "        allWeights = []\n",
    "        allbiases = []\n",
    "    for epoch in range(epocs):\n",
    "        if reportWeightChanges:\n",
    "            allWeights.append(sess.run(weightsvar))\n",
    "            allbiases.append(sess.run(biasvar))\n",
    "\n",
    "        shuffledRange = np.random.permutation(n_train)\n",
    "        y_one_hot_train = encode_one_hot(len(classes), Y_tr)\n",
    "        y_one_hot_validation = encode_one_hot(len(classes), Y_validation)\n",
    "        shuffledX = X_tr[shuffledRange,:]\n",
    "        shuffledY = y_one_hot_train[shuffledRange]\n",
    "        \n",
    "        for Xi, Yi in iterate_mini_batches(shuffledX, shuffledY, mini_batch_size):\n",
    "            sess.run(train_step, feed_dict={X_Bottleneck: Xi, Y_true: Yi})\n",
    "            # Every so often, print out how well the graph is training.\n",
    "            is_last_step = (i + 1 == how_many_training_steps)\n",
    "\n",
    "            if (i % eval_step_interval) == 0 or is_last_step:\n",
    "                train_accuracy, cross_entropy_value = sess.run([evaluation_step, cross_entropy],feed_dict={X_Bottleneck: Xi,Y_true: Yi})\n",
    "                validation_accuracy = sess.run(evaluation_step,feed_dict={X_Bottleneck: X_validation,Y_true: y_one_hot_validation})\n",
    "                print('%s: Step %d: Train accuracy = %.1f%%, Cross entropy = %f, Validation accuracy = %.2f%%' %\n",
    "                    (datetime.now(), i, train_accuracy * 100, cross_entropy_value, validation_accuracy * 100))\n",
    "            i+=1\n",
    "\n",
    "    if epocs > 0:\n",
    "        test_accuracy = sess.run(evaluation_step, feed_dict={X_Bottleneck: X_validation,Y_true:y_one_hot_validation })\n",
    "        print('Final test accuracy = %.1f%%' % (test_accuracy * 100))\n",
    "\n",
    "    target_class_probs = sess.run(class_probs,feed_dict={X_Bottleneck:targetFeatRep, Y_true:Y_target})\n",
    "    target_corr_pred = sess.run(correct_prediction, feed_dict={X_Bottleneck:targetFeatRep, Y_true:Y_target})\n",
    "\n",
    "    poison_class_probs = sess.run(class_probs,feed_dict={X_Bottleneck:poisonFeatRep, Y_true:Y_poison})\n",
    "    poison_corr_pred = sess.run(correct_prediction, feed_dict={X_Bottleneck:poisonFeatRep, Y_true:Y_poison})\n",
    "    \n",
    "\n",
    "    print('The target is now classified correctly:',target_corr_pred,'class probs:',target_class_probs)\n",
    "    print('The poison is now classified correctly:',poison_corr_pred,'class probs:',poison_class_probs)\n",
    "\n",
    "    print('Dist in feat space:',np.linalg.norm(targetFeatRep-poisonFeatRep))\n",
    "\n",
    "    if reportWeightChanges:\n",
    "        allWeights = np.array(allWeights)\n",
    "        allbiases = np.array(allbiases)\n",
    "        return target_class_probs, target_corr_pred, poison_class_probs, poison_corr_pred, allWeights, allbiases\n",
    "    else:\n",
    "        return  target_class_probs, target_corr_pred, poison_class_probs, poison_corr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c43f380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# source = \"C:/Users/crahu/Downloads/dogs-vs-cats/train/train/\"\n",
    "# d1=\"C:/Users/crahu/Downloads/dogs-vs-cats/train/train/Cats/\"\n",
    "# d2=\"C:/Users/crahu/Downloads/dogs-vs-cats/train/train/Dogs/\"\n",
    "# for image in os.listdir(source):\n",
    "#     if image.startswith('cat'):\n",
    "#         shutil.move(source + image,d1) \n",
    "#     else:\n",
    "#         shutil.move(source + image,d2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abb0e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb73d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fde2499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading data i.e. the train-test split!\n",
      "coeff_sim_inp is: 2.7086916123990835e-06\n",
      "iter: 0 | diff: 18.112 | obj: 18.112\n",
      " (0) Rel change =  1.00000e+05   |   lr = 1.27500e+05 |   obj = 1.8111627579e+01\n",
      "iter: 20 | diff: 13.445 | obj: 13.456\n",
      " (20) Rel change =  2.53030e-02   |   lr = 1.27500e+05 |   obj = 1.3456306164e+01\n",
      "iter: 40 | diff: 15.538 | obj: 15.557\n",
      " (40) Rel change =  3.52355e-02   |   lr = 1.27500e+05 |   obj = 1.5557102349e+01\n",
      "iter: 60 | diff: 11.325 | obj: 11.335\n",
      " (60) Rel change =  1.90560e-02   |   lr = 6.37500e+04 |   obj = 1.1335269247e+01\n",
      "iter: 80 | diff: 12.022 | obj: 12.034\n",
      " (80) Rel change =  2.75756e-02   |   lr = 6.37500e+04 |   obj = 1.2034397373e+01\n",
      "iter: 100 | diff: 7.761 | obj: 7.774\n",
      " (100) Rel change =  2.41156e-02   |   lr = 6.37500e+04 |   obj = 7.7737397389e+00\n",
      "iter: 120 | diff: 11.239 | obj: 11.253\n",
      " (120) Rel change =  2.03870e-02   |   lr = 6.37500e+04 |   obj = 1.1252524321e+01\n",
      "iter: 140 | diff: 8.813 | obj: 8.824\n",
      " (140) Rel change =  2.18841e-02   |   lr = 6.37500e+04 |   obj = 8.8244178187e+00\n",
      "iter: 160 | diff: 8.190 | obj: 8.204\n",
      " (160) Rel change =  2.89906e-02   |   lr = 6.37500e+04 |   obj = 8.2035720238e+00\n",
      "iter: 180 | diff: 8.748 | obj: 8.757\n",
      " (180) Rel change =  1.03752e-02   |   lr = 3.18750e+04 |   obj = 8.7566524556e+00\n",
      "iter: 200 | diff: 8.628 | obj: 8.638\n",
      " (200) Rel change =  1.36696e-02   |   lr = 3.18750e+04 |   obj = 8.6382641325e+00\n",
      "iter: 220 | diff: 4.747 | obj: 4.754\n",
      " (220) Rel change =  4.81969e-03   |   lr = 1.59375e+04 |   obj = 4.7539806740e+00\n",
      "iter: 240 | diff: 5.410 | obj: 5.416\n",
      " (240) Rel change =  6.56319e-03   |   lr = 1.59375e+04 |   obj = 5.4158734560e+00\n",
      "iter: 260 | diff: 4.995 | obj: 5.001\n",
      " (260) Rel change =  5.77470e-03   |   lr = 1.59375e+04 |   obj = 5.0006406655e+00\n",
      "iter: 280 | diff: 5.674 | obj: 5.679\n",
      " (280) Rel change =  5.35455e-03   |   lr = 1.59375e+04 |   obj = 5.6791912518e+00\n",
      "iter: 300 | diff: 3.474 | obj: 3.478\n",
      " (300) Rel change =  2.17518e-03   |   lr = 7.96875e+03 |   obj = 3.4782210958e+00\n",
      "iter: 320 | diff: 3.711 | obj: 3.715\n",
      " (320) Rel change =  2.20620e-03   |   lr = 7.96875e+03 |   obj = 3.7150770834e+00\n",
      "final diff: 2.605 | final obj: 2.609\n",
      "built poison for target 0 with diff: 2.60481\n",
      "coeff_sim_inp is: 2.7086916123990835e-06\n",
      "iter: 0 | diff: 17.624 | obj: 17.624\n",
      " (0) Rel change =  1.00000e+05   |   lr = 1.27500e+05 |   obj = 1.7624141693e+01\n",
      "iter: 20 | diff: 14.571 | obj: 14.583\n",
      " (20) Rel change =  3.13846e-02   |   lr = 1.27500e+05 |   obj = 1.4582656319e+01\n",
      "iter: 40 | diff: 8.835 | obj: 8.855\n",
      " (40) Rel change =  4.43240e-02   |   lr = 1.27500e+05 |   obj = 8.8546286943e+00\n",
      "iter: 60 | diff: 7.043 | obj: 7.058\n",
      " (60) Rel change =  2.16463e-02   |   lr = 6.37500e+04 |   obj = 7.0580322718e+00\n",
      "iter: 80 | diff: 6.682 | obj: 6.695\n",
      " (80) Rel change =  2.80568e-02   |   lr = 6.37500e+04 |   obj = 6.6946861397e+00\n",
      "iter: 100 | diff: 8.029 | obj: 8.037\n",
      " (100) Rel change =  1.96529e-02   |   lr = 3.18750e+04 |   obj = 8.0372152539e+00\n",
      "iter: 120 | diff: 8.281 | obj: 8.291\n",
      " (120) Rel change =  1.62368e-02   |   lr = 3.18750e+04 |   obj = 8.2911302507e+00\n",
      "iter: 140 | diff: 12.914 | obj: 12.922\n",
      " (140) Rel change =  9.85246e-03   |   lr = 3.18750e+04 |   obj = 1.2922036402e+01\n",
      "iter: 160 | diff: 7.190 | obj: 7.197\n",
      " (160) Rel change =  1.47463e-02   |   lr = 3.18750e+04 |   obj = 7.1971065098e+00\n",
      "iter: 180 | diff: 6.874 | obj: 6.882\n",
      " (180) Rel change =  1.23478e-02   |   lr = 3.18750e+04 |   obj = 6.8823584220e+00\n",
      "iter: 200 | diff: 5.952 | obj: 5.961\n",
      " (200) Rel change =  7.71552e-03   |   lr = 3.18750e+04 |   obj = 5.9612284990e+00\n",
      "iter: 220 | diff: 5.086 | obj: 5.092\n",
      " (220) Rel change =  4.11082e-03   |   lr = 1.59375e+04 |   obj = 5.0919307070e+00\n",
      "iter: 240 | diff: 6.271 | obj: 6.276\n",
      " (240) Rel change =  4.70895e-03   |   lr = 1.59375e+04 |   obj = 6.2759057674e+00\n",
      "iter: 260 | diff: 3.466 | obj: 3.470\n",
      " (260) Rel change =  2.19789e-03   |   lr = 7.96875e+03 |   obj = 3.4704091528e+00\n",
      "iter: 280 | diff: 3.744 | obj: 3.748\n",
      " (280) Rel change =  2.35958e-03   |   lr = 7.96875e+03 |   obj = 3.7476108460e+00\n",
      "final diff: 2.782 | final obj: 2.785\n",
      "built poison for target 1 with diff: 2.78157\n",
      "coeff_sim_inp is: 2.7086916123990835e-06\n",
      "iter: 0 | diff: 15.372 | obj: 15.372\n",
      " (0) Rel change =  1.00000e+05   |   lr = 1.27500e+05 |   obj = 1.5371661186e+01\n",
      "iter: 20 | diff: 13.966 | obj: 13.978\n",
      " (20) Rel change =  3.16117e-02   |   lr = 1.27500e+05 |   obj = 1.3978467935e+01\n",
      "iter: 40 | diff: 12.210 | obj: 12.222\n",
      " (40) Rel change =  3.62281e-02   |   lr = 1.27500e+05 |   obj = 1.2221698713e+01\n",
      "iter: 60 | diff: 12.323 | obj: 12.334\n",
      " (60) Rel change =  2.94160e-02   |   lr = 1.27500e+05 |   obj = 1.2334273863e+01\n",
      "iter: 80 | diff: 13.730 | obj: 13.749\n",
      " (80) Rel change =  6.99058e-02   |   lr = 1.27500e+05 |   obj = 1.3748510360e+01\n",
      "iter: 100 | diff: 13.740 | obj: 13.752\n",
      " (100) Rel change =  3.96620e-02   |   lr = 1.27500e+05 |   obj = 1.3751828021e+01\n",
      "iter: 120 | diff: 14.368 | obj: 14.380\n",
      " (120) Rel change =  3.57683e-02   |   lr = 1.27500e+05 |   obj = 1.4380068189e+01\n",
      "iter: 140 | diff: 11.897 | obj: 11.907\n",
      " (140) Rel change =  2.68232e-02   |   lr = 6.37500e+04 |   obj = 1.1906958544e+01\n",
      "iter: 160 | diff: 10.815 | obj: 10.824\n",
      " (160) Rel change =  1.47267e-02   |   lr = 6.37500e+04 |   obj = 1.0824044170e+01\n",
      "iter: 180 | diff: 10.794 | obj: 10.800\n",
      " (180) Rel change =  1.06040e-02   |   lr = 3.18750e+04 |   obj = 1.0800110717e+01\n",
      "iter: 200 | diff: 9.352 | obj: 9.358\n",
      " (200) Rel change =  1.21831e-02   |   lr = 3.18750e+04 |   obj = 9.3583121860e+00\n",
      "iter: 220 | diff: 7.681 | obj: 7.686\n",
      " (220) Rel change =  5.76263e-03   |   lr = 1.59375e+04 |   obj = 7.6858914222e+00\n",
      "iter: 240 | diff: 7.374 | obj: 7.379\n",
      " (240) Rel change =  4.76715e-03   |   lr = 1.59375e+04 |   obj = 7.3786485665e+00\n",
      "iter: 260 | diff: 7.313 | obj: 7.318\n",
      " (260) Rel change =  4.72939e-03   |   lr = 1.59375e+04 |   obj = 7.3179904778e+00\n",
      "iter: 280 | diff: 6.730 | obj: 6.735\n",
      " (280) Rel change =  4.37066e-03   |   lr = 1.59375e+04 |   obj = 6.7345776203e+00\n",
      "iter: 300 | diff: 6.891 | obj: 6.896\n",
      " (300) Rel change =  5.36104e-03   |   lr = 1.59375e+04 |   obj = 6.8958743567e+00\n",
      "iter: 320 | diff: 7.308 | obj: 7.313\n",
      " (320) Rel change =  8.89023e-03   |   lr = 1.59375e+04 |   obj = 7.3132140771e+00\n",
      "iter: 340 | diff: 6.393 | obj: 6.397\n",
      " (340) Rel change =  5.54782e-03   |   lr = 1.59375e+04 |   obj = 6.3972439445e+00\n",
      "iter: 360 | diff: 7.400 | obj: 7.405\n",
      " (360) Rel change =  6.45147e-03   |   lr = 1.59375e+04 |   obj = 7.4046458708e+00\n",
      "iter: 380 | diff: 6.739 | obj: 6.744\n",
      " (380) Rel change =  4.66708e-03   |   lr = 1.59375e+04 |   obj = 6.7436471289e+00\n",
      "iter: 400 | diff: 7.327 | obj: 7.332\n",
      " (400) Rel change =  5.26469e-03   |   lr = 1.59375e+04 |   obj = 7.3318368198e+00\n",
      "iter: 420 | diff: 7.903 | obj: 7.908\n",
      " (420) Rel change =  6.41744e-03   |   lr = 1.59375e+04 |   obj = 7.9078066888e+00\n",
      "iter: 440 | diff: 6.897 | obj: 6.902\n",
      " (440) Rel change =  6.63368e-03   |   lr = 1.59375e+04 |   obj = 6.9015393102e+00\n",
      "iter: 460 | diff: 5.431 | obj: 5.435\n",
      " (460) Rel change =  3.02216e-03   |   lr = 7.96875e+03 |   obj = 5.4350902386e+00\n",
      "iter: 480 | diff: 4.869 | obj: 4.872\n",
      " (480) Rel change =  2.11453e-03   |   lr = 7.96875e+03 |   obj = 4.8723714073e+00\n",
      "iter: 500 | diff: 4.608 | obj: 4.611\n",
      " (500) Rel change =  2.23880e-03   |   lr = 7.96875e+03 |   obj = 4.6110748071e+00\n",
      "iter: 520 | diff: 4.559 | obj: 4.562\n",
      " (520) Rel change =  2.84798e-03   |   lr = 7.96875e+03 |   obj = 4.5622710954e+00\n",
      "iter: 540 | diff: 4.699 | obj: 4.702\n",
      " (540) Rel change =  2.09765e-03   |   lr = 7.96875e+03 |   obj = 4.7021066715e+00\n",
      "iter: 560 | diff: 4.819 | obj: 4.822\n",
      " (560) Rel change =  2.37814e-03   |   lr = 7.96875e+03 |   obj = 4.8221567037e+00\n",
      "iter: 580 | diff: 4.911 | obj: 4.915\n",
      " (580) Rel change =  2.45192e-03   |   lr = 7.96875e+03 |   obj = 4.9145128444e+00\n",
      "iter: 600 | diff: 4.569 | obj: 4.572\n",
      " (600) Rel change =  2.58795e-03   |   lr = 7.96875e+03 |   obj = 4.5722083025e+00\n",
      "iter: 620 | diff: 4.141 | obj: 4.145\n",
      " (620) Rel change =  1.81034e-03   |   lr = 7.96875e+03 |   obj = 4.1445972921e+00\n",
      "iter: 640 | diff: 4.463 | obj: 4.466\n",
      " (640) Rel change =  2.65130e-03   |   lr = 7.96875e+03 |   obj = 4.4659817110e+00\n",
      "iter: 660 | diff: 5.538 | obj: 5.542\n",
      " (660) Rel change =  3.66274e-03   |   lr = 7.96875e+03 |   obj = 5.5416821115e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 680 | diff: 4.317 | obj: 4.320\n",
      " (680) Rel change =  2.50677e-03   |   lr = 7.96875e+03 |   obj = 4.3198497732e+00\n",
      "iter: 700 | diff: 4.800 | obj: 4.804\n",
      " (700) Rel change =  2.58770e-03   |   lr = 7.96875e+03 |   obj = 4.8036878416e+00\n",
      "iter: 720 | diff: 4.534 | obj: 4.537\n",
      " (720) Rel change =  2.61308e-03   |   lr = 7.96875e+03 |   obj = 4.5374904012e+00\n",
      "iter: 740 | diff: 4.572 | obj: 4.575\n",
      " (740) Rel change =  2.50495e-03   |   lr = 7.96875e+03 |   obj = 4.5748715025e+00\n",
      "iter: 760 | diff: 4.419 | obj: 4.422\n",
      " (760) Rel change =  2.26577e-03   |   lr = 7.96875e+03 |   obj = 4.4223603571e+00\n",
      "iter: 780 | diff: 4.638 | obj: 4.641\n",
      " (780) Rel change =  2.50739e-03   |   lr = 7.96875e+03 |   obj = 4.6413926068e+00\n",
      "iter: 800 | diff: 4.786 | obj: 4.790\n",
      " (800) Rel change =  3.05293e-03   |   lr = 7.96875e+03 |   obj = 4.7898116926e+00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-6376d57d9a25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    104\u001b[0m                 \u001b[0mbaseImg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_inp_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdo_optimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargetImg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseImg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxIter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcoeffSimInp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaveInterim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimageID\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjThreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'built poison for target %d with diff: %.5f'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-5d0939710176>\u001b[0m in \u001b[0;36mdo_optimization\u001b[1;34m(targetImg, baseImg, MaxIter, coeffSimInp, saveInterim, imageID, objThreshold)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mnew_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madam_one_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcurrentImage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mold_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatRepTarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtargetFeatRep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarFeatRepPL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarFeatRepPL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputCastImgTensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputCastImgTensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mnew_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdo_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputCastImgTensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputCastImgTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrentImage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mold_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatRepCurrentImage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mold_featRep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatRepTarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtargetFeatRep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarFeatRepPL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarFeatRepPL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;31m# The backward step in the forward-backward iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-f8edefb09e3a>\u001b[0m in \u001b[0;36mdo_forward\u001b[1;34m(sess, grad_op, inputCastImgTensor, currentImage, featRepCurrentImage, featRepTarget, tarFeatRepPL, learning_rate)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdo_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputCastImgTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrentImage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatRepCurrentImage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatRepTarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarFeatRepPL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"\"\"helper function doing the forward step in the FWD-BCKWD splitting algorithm\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mgrad_now\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0minputCastImgTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcurrentImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarFeatRepPL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfeatRepTarget\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m      \u001b[1;31m#evaluate the gradient at the current point\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mcurrentImage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrentImage\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_now\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m                                  \u001b[1;31m#gradient descent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcurrentImage\u001b[0m                                                                                         \u001b[1;31m#get the new current point\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    969\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1190\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1192\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1371\u001b[0m                            run_metadata)\n\u001b[0;32m   1372\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1375\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1377\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1378\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1360\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1361\u001b[0m                                       target_list, run_metadata)\n\u001b[0;32m   1362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1451\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1452\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1453\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1454\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1455\u001b[0m                                             run_metadata)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "this script containts the one shot kill poison attack\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import os\n",
    "\n",
    "#location of dog and fish directories\n",
    "dogDir = \"C:/Users/crahu/Downloads/dogs-vs-cats/train/train/Dogs/\"\n",
    "catDir = \"C:/Users/crahu/Downloads/dogs-vs-cats/train/train/Cats/\"\n",
    "#parameters\n",
    "firsTime = False #flag that if true, will load the raw images from the directories and extract the features and prepare the inputs for training.\n",
    "startFromClosest = False #if ture, for every target, we would select the base to be the closest instance from the other class in the test set. Closeness is measured by L2 distance in feature space reps\n",
    "threshold = 3.5 #threshold for L2 distance in feature space\n",
    "\n",
    "\n",
    "if startFromClosest == False:\n",
    "    #these are some preferred images as base instances which will be used for generating poison instances for the attacks\n",
    "    class_dog_base_id_in_test = [10, 406, 493]\n",
    "    class_cat_base_id_in_test = [10,200,300]\n",
    "\n",
    "if firsTime:\n",
    "    #load the images into numpy arrays\n",
    "    allDogs = load_images_from_directory('dog', dogDir)\n",
    "    allCats = load_images_from_directory('cat', catDir)\n",
    "    print(allDogs.dtype)\n",
    "    #remove the ones that might cause an issue with inception - these are the ones which have less than 3 dimensions\n",
    "#     allDogs = clean_data(X=allDogs)\n",
    "#     allCats = clean_data(X=allCats)\n",
    "\n",
    "    #save the images to file for future use\n",
    "    directory = \"D:/Courses/Spring 2022/Trustworthy ML/Final_project/Images/\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    np.save(directory+'dogInput.npy',allDogs)\n",
    "    directory = \"D:/Courses/Spring 2022/Trustworthy ML/Final_project/Images/\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    np.save(directory+'catInput.npy',allCats)\n",
    "\n",
    "    print(allDogs[0])\n",
    "    print(allCats[0])\n",
    "    #get the feature representations and save them\n",
    "    dogFeats = get_feat_reps(X=allDogs, class_t='dog')\n",
    "    directory = \"D:/Courses/Spring 2022/Trustworthy ML/Final_project/Images/\"\n",
    "    if not os.path.exists(directory):\n",
    "         os.makedirs(directory)\n",
    "    np.save(directory+'dogFeats.npy',dogFeats)\n",
    "    catFeats = get_feat_reps(X=allCats, class_t='cat')\n",
    "    directory = \"D:/Courses/Spring 2022/Trustworthy ML/Final_project/Images/\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    np.save(directory+'catFeats.npy',catFeats)\n",
    "\n",
    "    #load the bottleneck tensors and do the train test split and save it\n",
    "    X_tr, X_test, X_inp_tr, X_inp_test, Y_tr, Y_test = load_bottleNeckTensor_data(directory=\"D:/Courses/Spring 2022/Trustworthy ML/Final_project/Images/\",saveEm=True)\n",
    "\n",
    "\n",
    "\n",
    "#load the training and test data\n",
    "directorySaving = \"D:/Courses/Spring 2022/Trustworthy ML/Final_project/XY/\"\n",
    "all_datas = ['X_tr_feats', 'X_tst_feats', 'X_tr_inp', 'X_tst_inp', 'Y_tr', 'Y_tst']\n",
    "X_tr = np.load(directorySaving+all_datas[0]+'.npy',allow_pickle=True)\n",
    "X_test = np.load(directorySaving+all_datas[1]+'.npy',allow_pickle=True)\n",
    "X_inp_tr = np.load(directorySaving+all_datas[2]+'.npy',allow_pickle=True)\n",
    "X_inp_test = np.load(directorySaving+all_datas[3]+'.npy',allow_pickle=True)\n",
    "Y_tr = np.load(directorySaving+all_datas[4]+'.npy',allow_pickle=True)\n",
    "Y_test = np.load(directorySaving+all_datas[5]+'.npy',allow_pickle=True)\n",
    "print('done loading data i.e. the train-test split!')\n",
    "\n",
    "\n",
    "# for i,img in enumerate(X_inp_test):\n",
    "#  misc.imsave('./forFindingBases/%d.jpeg'%i,img)\n",
    "\n",
    "#some intializations before we actually make the poisons\n",
    "allPoisons = []\n",
    "alldiffs = []\n",
    "directoryForPoisons = \"D:/Courses/Spring 2022/Trustworthy ML/Final_project/Poison_Images/\"\n",
    "if not os.path.exists(directoryForPoisons):\n",
    "    os.makedirs(directoryForPoisons)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    diff = 100\n",
    "    maxTriesForOptimizing = 10\n",
    "    counter = 0\n",
    "    targetImg = X_inp_test[i]\n",
    "    usedClosest = False\n",
    "    while (diff > threshold) and (counter < maxTriesForOptimizing):\n",
    "        if Y_test[i] == 1 and counter<len(class_dog_base_id_in_test):\t\t\t\t#if target is fish, the poison base should be a dog\n",
    "            baseImg = X_inp_test[class_dog_base_id_in_test[counter]]\n",
    "        elif Y_test[i] == 0 and counter<len(class_cat_base_id_in_test):\n",
    "            baseImg = X_inp_test[class_cat_base_id_in_test[counter]]\n",
    "        else:\n",
    "            if not usedClosest:\n",
    "                ind = closest_to_target_from_class( classBase = 1 - Y_test[i] , targetFeatRep= X_test[i] ,allTestFeatReps=X_test, allTestClass=Y_test)\n",
    "                baseImg = X_inp_test[ind]\n",
    "                usedClosest = True\n",
    "            else:\n",
    "                print('Using random base!')\n",
    "                classBase = 1 - Y_test[i]\n",
    "                possible_indices = np.argwhere(Y_test == classBase)[:,0]\n",
    "                ind = np.random.randint(len(possible_indices))\n",
    "                ind = possible_indices[ind]\n",
    "                baseImg = X_inp_test[ind]\n",
    "\n",
    "        img, diff = do_optimization(targetImg, baseImg, MaxIter=1500,coeffSimInp=0.2, saveInterim=False, imageID=i, objThreshold=2.9)\n",
    "        print('built poison for target %d with diff: %.5f'%(i,diff))\n",
    "        counter += 1\n",
    "    # save the image to file and keep statistics\n",
    "    allPoisons.append(img)\n",
    "    alldiffs.append(diff)\n",
    "    name = \"%d_%.5f\"%(i,diff)\n",
    "    import imageio\n",
    "    imageio.imwrite(directoryForPoisons+name+'.jpeg',img)\n",
    "    #misc.imsave(, img)\n",
    "    \n",
    "allPoisons = np.array(allPoisons)\n",
    "alldiffs = np.array(alldiffs)\n",
    "np.save('all_poisons.npy', allPoisons)\n",
    "np.save('alldiffs.npy', alldiffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e9aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
